前提：已安装Python3.7 & pycharm
简要的DOS命令：
退出当前虚拟环境：deactivate
下载virtualenvwrapper工具包：pip install virtualenvwrapper-win
创建新环境：mkvirtualenv xxx
列出虚拟环境：lsvirtualenv / workon
查看配置环境的存储位置：echo %WORKON_HOME%
查看pip安装表：lssitepackages
更新pip：python -m pip install --upgrade pip（若更新失败先还原成安全版本：python -m ensurepip，再执行更新命令）
——————————————————————————————————————————————————————————————————————————————————————————————————————————————————
1.环境中安装tushare库：
安装tushare：pip install tushare / pip install tushare-i（若超时则用此命令）
更新tushare：pip install tushare --upgrade
查看版本script：print(tushare.__version__);


2.tushare社区门户的注册：
访问Tushare社区门户（https://waditu.com），并注册账户；
点击"个人主页"，点击"接口token"即可获取自己的token;(注：token是调取数据的唯一凭证，如发现盗用，可点击“刷新”失效之前的token。)


3.调取数据：
导包：import tushare as ts [版本>1.2.10]
设置token：ts.set_token('xxx') [第一次/失效后调用，无需重复设置]
初始化pro接口：pro=ts.pro_api('xxx')

df = pro.trade_cal(exchange='', start_date='20180901', end_date='20181001', fields='exchange,cal_date,is_open,pretrade_date', is_open='0')
或
df = pro.query('trade_cal', exchange='', start_date='20180901', end_date='20181001', fields='exchange,cal_date,is_open,pretrade_date', is_open='0')

Tushare行情等时间数据，一般有两个常用参数：trade_date和ts_code(交易日期和证券代码)
如果提取部分个股的历史数据用ts_code，加上开始和结束日期方便提取数据。
如果获取所有历史数据用trade_date，股票有3800多个，需循环3800多次，每年的交易日就220天左右，所以效率更高。
import tushare as ts
pro = ts.pro_api('939444dd20bfcdb58d9076ef21a3f0395d937193da1f8f000d94d20c')
##daily()获取2020年3月25号的交易记录（120积分获取5k条data）
#print(pro.daily(trade_date='20211112'))

#trade_cal()获取20200101～20200401之间的有效交易日
df = pro.trade_cal(exchange='SSE', is_open='1',
                   start_date='20200101',
                   end_date='20200401',
                   fields='cal_date')

#head()默参设置n=5，即提取前5条数据
# print(df.head())
# print(df['cal_date'][0])
# print(type(df['cal_date'][0]))


4.数据入库（MySQL）：
安装sqlalchemy、mysqlclient包；

安装MySQL：
请按照网上流程安装MySQL，以下是一些简单的mysql命令：
查询mysql版本：mysqladmin --version
开启mysql服务：net start xxx(数据库服务名称)
登录mysql：mysql -u root -p，并输入密码；

编写入库代码：
由于用了sqlalchemy，这个过程非常简单。用户无需首先在数据库中建表就可以执行数据入库，但这种默认方式所创建的数据表并不是最优的数据结构，可以参考第4条进行优化。
res = df.to_sql('stock_basic', engine_ts, index=False, if_exists='append', chunksize=5000)

数据结构优化：
对于默认创建的表，会有一些不太符合实际应用，比如数据结构类型比较单一，没有主键和索引等约束，没有comments等等。我们可以在数据库客户端对所建立的表进行修改，使其符合实际的最优设计。
比如将一般的str转成varchar2类型，而不是text类型。

实现本地调度程序：
完成数据调取接口和入库程序之后，可开发一个调取程序，让系统的调度系统来定时从tushare拉取数据。比如windows我们可以用计划任务，Linux可以使用crontab。

完整的入库程序，包括数据提取入库，以及从mysql读到pandas dataframe，提供了一个完整的py文件供参考。


